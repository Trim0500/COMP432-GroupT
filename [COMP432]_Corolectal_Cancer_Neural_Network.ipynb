{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Corolectal Cancer Pre-trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This notebook contains the implementation for the first pre-trained CNN encoder outlined as the first task of the project proposal. The architecture selected is ResNet and the implementation used comes from the `torchvision` module.\n",
        "\n",
        "### Below are 4 different attempts at pre-training the model to find the ideal loop, optimizer and loss function that will yield the best performance for the model. The following 4 optimizers were selected.\n",
        "- #### **SGD**\n",
        "- #### **SGD + Momentum**\n",
        "- #### **RMSProp**\n",
        "- #### **Adam**\n",
        "\n",
        "### Each loop utilizes the Categorical cross Entropy (CCE) loss function due to the presence of 3 distinct classes in the dataset (MUS, NORM, STR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH3QudoHyrpM",
        "outputId": "07bbc2ee-d7a7-4e06-90d0-c9d11d4beee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.cuda.is_available(): True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "from torch.optim import SGD, Adam, RMSprop\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "print(f\"torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# [Task 1]: Import and initialize ResNet50\n",
        "resnet_corolectal_cancer_model = resnet50(weights=None)\n",
        "'''\n",
        "Note that by default the ResNet implementations from PyTorch's source code follow the ImaegNet fully connected layer specification of 2048x1000.\n",
        "    Therefore, for our project, we need to change it to use 3 classes according to the first dataset (MUS, NORM, STR).\n",
        "    See the source code for the base class here (https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py).\n",
        "    Stack Overflow post here (https://stackoverflow.com/questions/68980724/the-number-of-classes-in-pytorch-pretrained-model).\n",
        "\n",
        "    Additionally, we will need to remove the last layer to be able to pass the features to a different learning algorithm in task 2.\n",
        "    Here is a Stack Overflow post about it (https://stackoverflow.com/questions/52548174/how-to-remove-the-last-fc-layer-from-a-resnet-model-in-pytorch).\n",
        "\n",
        "'''\n",
        "resnet_corolectal_cancer_model.fc = torch.nn.Linear(2048, 3)\n",
        "resnet_corolectal_cancer_model.to(device=device)\n",
        "resnet_corolectal_cancer_model.train()\n",
        "\n",
        "# [Task 1]: Import and initialize the optimizer algorithms\n",
        "'''\n",
        "Hyperparameters for vanilla SGD recommended settings: learning rate = 0.001\n",
        "                                                      L2 regularizer penalty = 1e-6\n",
        "                                                      Batch Size = 100\n",
        "'''\n",
        "learning_rate = 0.001\n",
        "l2_regularizer = 1e-6\n",
        "batch_size = 32\n",
        "num_epochs = 1 \n",
        "\n",
        "sgd_no_momentum = SGD(resnet_corolectal_cancer_model.parameters(), lr=learning_rate, weight_decay=l2_regularizer, differentiable=True)\n",
        "\n",
        "'''\n",
        "Hyperparameters for SGD + momentum recommended settings: learning rate = 0.001\n",
        "                                                         L2 regularizer penalty = 1e-6\n",
        "                                                         Batch Size = 100\n",
        "                                                         Momentum = 0.9\n",
        "                                                         Nesterov = true\n",
        "'''\n",
        "sgd_momentum = 0.9\n",
        "sgd_momentum_use_nesterov = True\n",
        "\n",
        "sgd_momentum = SGD(resnet_corolectal_cancer_model.parameters(),\n",
        "                   lr=learning_rate,\n",
        "                   weight_decay=l2_regularizer,\n",
        "                   momentum=sgd_momentum,\n",
        "                   nesterov=sgd_momentum_use_nesterov,\n",
        "                   differentiable=True)\n",
        "\n",
        "'''\n",
        "Hyperparameters for Adam recommended settings: learning rate = 0.001\n",
        "                                               L2 regularizer penalty = 1e-6\n",
        "                                               Batch Size = 100\n",
        "                                               Beta 1 (Momentum) = 0.9\n",
        "                                               Beta 2 (RMS decay rate) = 0.999\n",
        "                                               Division stablizer = 1e-8\n",
        "'''\n",
        "adam_betas = (0.9, 0.999)\n",
        "epsilon_division_stablizer = 1e-8\n",
        "\n",
        "adam = Adam(resnet_corolectal_cancer_model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=l2_regularizer,\n",
        "            betas=adam_betas,\n",
        "            eps=epsilon_division_stablizer,\n",
        "            differentiable=True)\n",
        "\n",
        "'''\n",
        "Hyperparameters for RSMProp recommended settings: learning rate = 0.001\n",
        "                                                  L2 regularizer penalty = 1e-6\n",
        "                                                  Batch Size = 100\n",
        "                                                  Decay rate = 0.999\n",
        "                                                  Division stablizer = 1e-8\n",
        "'''\n",
        "rmsprop_decay_rate = adam_betas[1]\n",
        "\n",
        "rmsprop = RMSprop(resnet_corolectal_cancer_model.parameters(),\n",
        "                  lr=learning_rate,\n",
        "                  weight_decay=l2_regularizer,\n",
        "                  alpha=rmsprop_decay_rate,\n",
        "                  eps=epsilon_division_stablizer,\n",
        "                  differentiable=True)\n",
        "\n",
        "# [Task 1]: Import and initialize the t-SNE visualization algorithm\n",
        "tsne = TSNE(random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pyHyejrE4p2Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Classes Detected: 3, CHECK\n",
            "\t> MUS: 2000 samples\n",
            "\t> NORM: 2000 samples\n",
            "\t> STR: 2000 samples\n",
            "[INFO] Train DataLoader is working: CHECK\n",
            "\t> Inputs size: torch.Size([32, 3, 224, 224]), \n",
            "\t> Labels size: torch.Size([32])\n",
            "[INFO] Test DataLoader is working: CHECK\n",
            "\t> Inputs size: torch.Size([32, 3, 224, 224]), \n",
            "\t> Labels size: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Source(s):\n",
        "    - Key Steps in Data Preprocessing: https://www.techtarget.com/searchdatamanagement/definition/data-preprocessing \n",
        "'''\n",
        "# Optimizers\n",
        "optimizer = RMSprop(resnet_corolectal_cancer_model.parameters(), lr=learning_rate, weight_decay=l2_regularizer)\n",
        "\n",
        "# Preprocessing transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet\n",
        "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
        "    transforms.ToTensor(),  \n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet Normalization\n",
        "])\n",
        "\n",
        "dataset_root = 'Datasets/Corolectal Cancer/'\n",
        "if not os.path.exists(dataset_root):\n",
        "    raise FileNotFoundError(f\"Dataset directory '{dataset_root}' does not exist.\")\n",
        "\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=dataset_root, transform=transform)\n",
        "\n",
        "# Data Profiling: Check number of classes and their album size\n",
        "if len(full_dataset) == 0:\n",
        "    raise ValueError(\"The dataset is empty. Please check the image files.\")\n",
        "\n",
        "num_classes = len(full_dataset.classes)\n",
        "if num_classes == 0:\n",
        "    raise ValueError(\"Classes Detected: FAILED\")\n",
        "else:\n",
        "    print(f\"[INFO] Classes Detected: {num_classes}, CHECK\")\n",
        "\n",
        "# Display full dataset size\n",
        "class_counts = np.bincount(full_dataset.targets)\n",
        "for i, count in enumerate(class_counts):\n",
        "    print(f\"\\t> {full_dataset.classes[i]}: {count} samples\")\n",
        "\n",
        "# Data Cleansing: Conditions to meet otherwise discarded warning\n",
        "min_samples = 5  \n",
        "classes_to_remove = [full_dataset.classes[i] for i, count in enumerate(class_counts) if count < min_samples]\n",
        "if classes_to_remove:\n",
        "    print(f\"[WARNING] Classes to remove due to low sample size: {classes_to_remove}\")\n",
        "\n",
        "# Data Validation: Split 80:20, DataLoaders for train/test\n",
        "train_size = int(0.8 * len(full_dataset))  \n",
        "test_size = len(full_dataset) - train_size  \n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def check_dataloader(dataloader, name):\n",
        "    try:\n",
        "        inputs, labels = next(iter(dataloader))\n",
        "        print(f\"[INFO] {name} DataLoader is working: CHECK\\n\\t> Inputs size: {inputs.size()}, \\n\\t> Labels size: {labels.size()}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"[ERROR] {name} DataLoader failed: {e}\")\n",
        "\n",
        "check_dataloader(train_dataloader, \"Train\")\n",
        "check_dataloader(test_dataloader, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SGD + Momentum Optimizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Starting training w/SGD + Momentum... CHECK\n",
            "[INFO] Epoch 1/1, Loss: 1.1436, Accuracy: 33.4167\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "print(\"[INFO] Starting training w/SGD + Momentum... CHECK\")\n",
        "\n",
        "resnet_corolectal_cancer_model.train() \n",
        "\n",
        "sgd_momentum_losses = []\n",
        "\n",
        "sgd_momentum_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    total_epoch_loss = 0.0  # Track loss for the epoch\n",
        "    \n",
        "    total_epoch_acc = 0.0  # Track accuracy for the epoch\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device) \n",
        "\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        outputs = resnet_corolectal_cancer_model(inputs)  # Forward pass\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)  # Calculate loss\n",
        "        loss.backward()  # Backward pass to compute gradients\n",
        "        \n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "        total_epoch_loss += loss.item()\n",
        "\n",
        "        softmax_confidence_scores = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        label_prediction = torch.argmax(softmax_confidence_scores, dim=1).view(-1)\n",
        "        total_epoch_acc += ((label_prediction == labels).sum().item() / len(labels)) * 100\n",
        "\n",
        "    num_batches = len(train_dataloader)\n",
        "    sgd_momentum_losses.append(total_epoch_loss / num_batches)\n",
        "\n",
        "    sgd_momentum_accuracies.append(total_epoch_acc / num_batches)\n",
        "\n",
        "    print(f\"[INFO] Epoch {epoch + 1}/{num_epochs}, Loss: {sgd_momentum_losses[epoch]:.4f}, Accuracy: {sgd_momentum_accuracies[epoch]:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RMSProp Optimizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "print(\"[INFO] Starting training... CHECK\")\n",
        "for epoch in range(num_epochs):  \n",
        "    resnet_corolectal_cancer_model.train() \n",
        "    total_epoch_loss = 0.0  # Track loss for the epoch\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device) \n",
        "\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        outputs = resnet_corolectal_cancer_model(inputs)  # Forward pass\n",
        "        \n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)  # Calculate loss\n",
        "        \n",
        "        loss.backward()  # Backward pass to compute gradients\n",
        "        optimizer.step()  # Update model parameters using gradients\n",
        "\n",
        "        total_epoch_loss += loss.item()  \n",
        "\n",
        "    print(f\"[INFO] Epoch {epoch + 1}/{num_epochs}, Loss: {total_epoch_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "print(\"[INFO] Starting evaluation... CHECK\")\n",
        "resnet_corolectal_cancer_model.eval()  \n",
        "with torch.no_grad(): \n",
        "    test_loss = 0.0 \n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  \n",
        "        \n",
        "        outputs = resnet_corolectal_cancer_model(inputs)  # Forward pass\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)  \n",
        "        \n",
        "        test_loss += loss.item()  \n",
        "\n",
        "    average_test_loss = test_loss / len(test_dataloader)\n",
        "    print(f\"[INFO] Test Loss: {average_test_loss:.4f}, CHECK\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
